{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2356f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372ad4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    \"\"\"\n",
    "    Q, K, V shapes: (batch, seq_len, d_k)\n",
    "    \"\"\"\n",
    "\n",
    "    d_k = Q.size(-1)\n",
    "\n",
    "    # Step 1: raw attention scores (QK^T)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "\n",
    "    # Step 2: scale scores\n",
    "    scaled_scores = scores / math.sqrt(d_k)\n",
    "\n",
    "    # Step 3: softmax to get weights\n",
    "    attn_weights = F.softmax(scaled_scores, dim=-1)\n",
    "\n",
    "    # Step 4: multiply by V\n",
    "    output = torch.matmul(attn_weights, V)\n",
    "\n",
    "    return output, attn_weights, scores, scaled_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fffc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "seq_len = 5\n",
    "d_k = 4\n",
    "\n",
    "# random Q, K, V\n",
    "Q = torch.randn(batch, seq_len, d_k)\n",
    "K = torch.randn(batch, seq_len, d_k)\n",
    "V = torch.randn(batch, seq_len, d_k)\n",
    "\n",
    "output, attn_weights, scores, scaled_scores = scaled_dot_product_attention(Q, K, V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c55a19",
   "metadata": {},
   "source": [
    "A. Attention Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e589dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (Softmax):\n",
      " tensor([[[0.0953, 0.0583, 0.1108, 0.1139, 0.6217],\n",
      "         [0.7757, 0.0969, 0.0894, 0.0135, 0.0246],\n",
      "         [0.3436, 0.0518, 0.1023, 0.2252, 0.2771],\n",
      "         [0.1064, 0.0805, 0.0728, 0.5460, 0.1942],\n",
      "         [0.0990, 0.1313, 0.1625, 0.2648, 0.3423]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention Weights (Softmax):\\n\", attn_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5743a",
   "metadata": {},
   "source": [
    "B. Output Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883fcf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Vectors:\n",
      " tensor([[[-0.5819,  0.1432, -0.1883, -0.1889],\n",
      "         [-0.1706, -0.4788, -1.4440, -0.5544],\n",
      "         [-0.3814, -0.2530, -0.5871, -0.1538],\n",
      "         [-0.2771, -0.2069,  0.0550,  0.1046],\n",
      "         [-0.2146,  0.2131, -0.2903, -0.1948]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutput Vectors:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ab5b2",
   "metadata": {},
   "source": [
    "C. Softmax Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26ff312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Softmax Stability Check:\n",
      "Max |raw scores| before scaling : 6.129274368286133\n",
      "Max |scaled scores| after scaling: 3.0646371841430664\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSoftmax Stability Check:\")\n",
    "print(\"Max |raw scores| before scaling :\", scores.abs().max().item())\n",
    "print(\"Max |scaled scores| after scaling:\", scaled_scores.abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407f566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b67e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
